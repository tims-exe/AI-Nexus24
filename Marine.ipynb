{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEb63B7Zx1SU",
        "outputId": "ff39a7fb-a6ef-474e-a07d-77af45b0d65d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.36.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io) (0.36.0)\n",
            "Installing collected packages: tensorflow_io\n",
            "Successfully installed tensorflow_io-0.36.0\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow_io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i3TEZpD9_Idj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2VNba-eWUZIy"
      },
      "outputs": [],
      "source": [
        "def load_wav_16k_mono(filename):\n",
        "\n",
        "    file_contents = tf.io.read_file(filename)\n",
        "\n",
        "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
        "\n",
        "    wav = tf.squeeze(wav, axis=-1)\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "\n",
        "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
        "    return wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dFfDGcdUyhOv"
      },
      "outputs": [],
      "source": [
        "Mir = os.path.join('data', 'Leptonychotes_weddellii')\n",
        "NMir = os.path.join('data', 'trial')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YOf_TJDAo_bM"
      },
      "outputs": [],
      "source": [
        "m = tf.data.Dataset.list_files(Mir+'/*.wav')\n",
        "nm = tf.data.Dataset.list_files(NMir+'/*.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gbpyhzqIpNgP"
      },
      "outputs": [],
      "source": [
        "positives = tf.data.Dataset.zip((m, tf.data.Dataset.from_tensor_slices(tf.ones(len(m)))))\n",
        "negatives = tf.data.Dataset.zip((nm, tf.data.Dataset.from_tensor_slices(tf.zeros(len(nm)))))\n",
        "data = positives.concatenate(negatives)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aWn3q_cpr8x"
      },
      "outputs": [],
      "source": [
        "lengths = []\n",
        "for file in os.listdir(os.path.join('data', 'Leptonychotes_weddellii')):\n",
        "    tensor_wave = load_wav_16k_mono(os.path.join('data', 'trial', file))\n",
        "    lengths.append(len(tensor_wave))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vi_usfc-taWp"
      },
      "outputs": [],
      "source": [
        "def preprocess(file_path, label):\n",
        "    wav = load_wav_16k_mono(file_path)\n",
        "    wav = wav[:48000]\n",
        "    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
        "    wav = tf.concat([zero_padding, wav],0)\n",
        "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
        "    return spectrogram, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPfW3Tk4t46a"
      },
      "outputs": [],
      "source": [
        "filepath, label = negatives.shuffle(buffer_size=10000).as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2yr9HocuWC2"
      },
      "outputs": [],
      "source": [
        "spectrogram, label = preprocess(filepath, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKoKRSGSv0NJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,20))\n",
        "plt.imshow(tf.transpose(spectrogram)[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLldW5e680Du",
        "outputId": "8057f17e-91f8-4bfe-8e63-7843d38813d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
          ]
        }
      ],
      "source": [
        "data = data.map(preprocess)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=1000)\n",
        "data = data.batch(16)\n",
        "data = data.prefetch(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nji3-WfH82HV",
        "outputId": "da97b4d0-ad8e-467d-86e4-54db5c9ee86a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "21.0"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)*.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3Qe1Z4q84rv"
      },
      "outputs": [],
      "source": [
        "train = data.take(21)\n",
        "test = data.skip(21).take(9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ6My4-69Snd"
      },
      "outputs": [],
      "source": [
        "samples, labels = train.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijcWsKS-9YNC",
        "outputId": "cade831b-d731-423b-c6a6-84ad1ac30fe0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(16, 1491, 257, 1)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samples.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ73vJ6i_Gl6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCU-zGbyB1yU"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(1491, 257,1)))\n",
        "model.add(Conv2D(16, (3,3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ywja8pS3B2Kz"
      },
      "outputs": [],
      "source": [
        "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNcuivFgCBjU",
        "outputId": "6423f63d-e1ed-492e-c6bf-249ff4aed632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 1489, 255, 16)     160       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 1487, 253, 16)     2320      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6019376)           0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                385240128 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 385242673 (1.44 GB)\n",
            "Trainable params: 385242673 (1.44 GB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_hVMQv91Pm3",
        "outputId": "cd580050-3e67-4ef4-b5e3-3b503ab78d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(train, epochs=2, validation_data=test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n70WSpCp1QBU"
      },
      "outputs": [],
      "source": [
        "X_test, y_test = test.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4ZVkCcdZv3b"
      },
      "outputs": [],
      "source": [
        "yhat = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5QIsDWxZyJE"
      },
      "outputs": [],
      "source": [
        "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekNCEHsNaapC"
      },
      "outputs": [],
      "source": [
        "def load_mp3_16k_mono(filename):\n",
        "    res = tfio.audio.AudioIOTensor(filename)\n",
        "\n",
        "    tensor = res.to_tensor()\n",
        "    tensor = tf.math.reduce_sum(tensor, axis=1) / 2\n",
        "\n",
        "    sample_rate = res.rate\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "\n",
        "    wav = tfio.audio.resample(tensor, rate_in=sample_rate, rate_out=16000)\n",
        "    return wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taFFEweyagzR"
      },
      "outputs": [],
      "source": [
        "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSNL4O02airS"
      },
      "outputs": [],
      "source": [
        "samples, index = audio_slices.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxtHOp45drOC"
      },
      "outputs": [],
      "source": [
        "mp3 = os.path.join('data', 'Recordings', '#22B')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2WVrVE7dwUS"
      },
      "outputs": [],
      "source": [
        "wav = load_mp3_16k_mono(mp3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUQdjDMTdxhK"
      },
      "outputs": [],
      "source": [
        "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SfSYZoidytb"
      },
      "outputs": [],
      "source": [
        "samples, index = audio_slices.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYe1PAl2akRe"
      },
      "outputs": [],
      "source": [
        "def preprocess_mp3(sample, index):\n",
        "    sample = sample[0]\n",
        "    zero_padding = tf.zeros([48000] - tf.shape(sample), dtype=tf.float32)\n",
        "    wav = tf.concat([zero_padding, sample],0)\n",
        "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
        "    return spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3BW1lMAamIa"
      },
      "outputs": [],
      "source": [
        "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=16000, sequence_stride=16000, batch_size=1)\n",
        "audio_slices = audio_slices.map(preprocess_mp3)\n",
        "audio_slices = audio_slices.batch(64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LprCeGW1antG"
      },
      "outputs": [],
      "source": [
        "yhat = model.predict(audio_slices)\n",
        "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovvAYLLSapDV"
      },
      "outputs": [],
      "source": [
        "from itertools import groupby"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxBx5Wc1arLr"
      },
      "outputs": [],
      "source": [
        "yhat = [key for key, group in groupby(yhat)]\n",
        "calls = tf.math.reduce_sum(yhat).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YcusosPatFy"
      },
      "outputs": [],
      "source": [
        "calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS4aiNK-avGr"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "for file in os.listdir(os.path.join('data', 'Recordings')):\n",
        "    FILEPATH = os.path.join('data','Recordings', file)\n",
        "\n",
        "    wav = load_mp3_16k_mono(FILEPATH)\n",
        "    audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
        "    audio_slices = audio_slices.map(preprocess_mp3)\n",
        "    audio_slices = audio_slices.batch(64)\n",
        "\n",
        "    yhat = model.predict(audio_slices)\n",
        "\n",
        "    results[file] = yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYbok8hxaxPi"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRxUOcL2ay2i"
      },
      "outputs": [],
      "source": [
        "class_preds = {}\n",
        "for file, logits in results.items():\n",
        "    class_preds[file] = [1 if prediction > 0.99 else 0 for prediction in logits]\n",
        "class_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTPxlxtqa96L"
      },
      "outputs": [],
      "source": [
        "postprocessed = {}\n",
        "for file, scores in class_preds.items():\n",
        "    postprocessed[file] = tf.math.reduce_sum([key for key, group in groupby(scores)]).numpy()\n",
        "postprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6M735sF9bAKj"
      },
      "outputs": [],
      "source": [
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o_xM4JHbApY"
      },
      "outputs": [],
      "source": [
        "with open('test1.csv', 'w', newline='') as f:\n",
        "    writer = csv.writer(f, delimiter=',')\n",
        "    writer.writerow(['recording', 'capuchin_calls'])\n",
        "    for key, value in postprocessed.items():\n",
        "        writer.writerow([key, value])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
